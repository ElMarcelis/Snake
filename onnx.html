<!DOCTYPE html>
<html>
<header>
    <title>ONNX Runtime JavaScript examples: Quick Start - Web (using script tag)</title>
</header>

<body>
    <!-- import ONNXRuntime Web from CDN -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <script>
        // use an async context to call onnxruntime functions.
        async function main() {
            try {
                // create a new session and load the specific model.
                //
                // the model in this example contains a single MatMul node
                // it has 2 inputs: 'a'(float32, 3x4) and 'b'(float32, 4x3)
                // it has 1 output: 'c'(float32, 3x3)
                const session = await ort.InferenceSession.create('./models/model.onnx');

                // prepare inputs. a tensor need its corresponding TypedArray as data
                const dataA = Float32Array.from([1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0]);

                const tensorA = new ort.Tensor('float32', dataA, [14]);

                // prepare feeds. use model input names as keys.
                const feeds = { input: tensorA };

                // feed inputs and run
                const results = await session.run(feeds);

                // str = JSON.stringify(results);
                str = JSON.stringify(results, null, 4); // (Optional) beautiful indented output.
                console.log(str); // Logs output to dev tools console.

                // read from results

                const dataOutput = results.output.data;
                document.write(`data of result tensor : ${dataOutput}`);

            } catch (e) {
                document.write(`failed to inference ONNX model: ${e}.`);
            }
        }

        main();
    </script>
</body>

</html>